{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python scripts\n",
    "from utils.functions_misc import *\n",
    "from utils.structural import * \n",
    "from utils.functional import * \n",
    "from utils.distance import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all matrices loaded correctly\n"
     ]
    }
   ],
   "source": [
    "# importing data\n",
    "main_dir = \"/Users/gabrielhaw/Connectome/\"\n",
    "# COBRE data\n",
    "subject_dir = main_dir + \"temp/\"\n",
    "participant_data = main_dir + \"misc/participants_CONNECT_matched_07052025.csv\"\n",
    "# distance matrices\n",
    "left_path = main_dir + \"geodesic_distances/Left_hemisphere\"\n",
    "right_path = main_dir + \"geodesic_distances/Right_hemisphere\"\n",
    "\n",
    "# processing distance matrices\n",
    "left_dist, right_dist = average_distances(left_path, right_path, participant_data)\n",
    "\n",
    "# loading in all final processed subject matrices\n",
    "fc_mat_dir = \"/Users/gabrielhaw/Connectome/subject_func_connectivity/\"\n",
    "sc_mat_dir = \"/Users/gabrielhaw/Connectome/subject_struct_connectivity/\"\n",
    "sc_path_dir = \"/Users/gabrielhaw/Connectome/subject_distances/\"\n",
    "\n",
    "# structural, functional connectivity & distances for each hemisphere (r: right, l: left)\n",
    "lmatsc, rmatsc = struct_connect(sc_mat_dir)\n",
    "lmatfc, rmatfc = funct_connect(fc_mat_dir)\n",
    "llength, rlength = struct_connect(sc_path_dir)\n",
    "\n",
    "print(\"all matrices loaded correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structural:\n",
      "Total edges in G: 4613.0\n",
      "Total edges in Gc: 2306.0\n",
      "Total edges in G: 4615.0\n",
      "Total edges in Gc: 2307.0\n",
      "functional:\n",
      "Edges removed: 0/50625 (0.0%)\n",
      "Edges removed: 0/49729 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# distance-dependent consensus matrices \n",
    "print(\"structural:\")\n",
    "_, _, structural_left, _ = process_hemisphere(lmatsc, left_dist, nbins=41)\n",
    "_, _, structural_right, _ = process_hemisphere(rmatsc, right_dist, nbins=41)\n",
    "\n",
    "print(\"functional:\")\n",
    "# functional connectivity matrics\n",
    "functional_left, functional_right = fconstruct_consensus(lmatfc, sthresh=0), fconstruct_consensus(rmatfc, sthresh=0)\n",
    "# final correlation matrices\n",
    "corrl, corrr = impute(functional_left),  impute(functional_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielhaw/ConnectomeCode/working/.venv/lib/python3.12/site-packages/brainspace/gradient/embedding.py:206: UserWarning: Affinity is not symmetric. Making symmetric.\n",
      "  warnings.warn('Affinity is not symmetric. Making symmetric.')\n",
      "/Users/gabrielhaw/ConnectomeCode/working/.venv/lib/python3.12/site-packages/brainspace/gradient/embedding.py:206: UserWarning: Affinity is not symmetric. Making symmetric.\n",
      "  warnings.warn('Affinity is not symmetric. Making symmetric.')\n"
     ]
    }
   ],
   "source": [
    "# left hemisphere embedding, Brainspace\n",
    "embedding_left = gradient_(corrl, sparsity=0.9, kernel=None, n_components = 3, approach=\"le\", z_score=True, savedf=False)\n",
    "# left hemisphere embedding, Brainspace\n",
    "embedding_right = gradient_(corrr, sparsity=0.9, kernel=None, n_components = 3, approach=\"le\", z_score=True, savedf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variograms\n",
    "global_variogram(left_dist, structural_left, sigma=0.1, n_bins=20, binmethod=\"uniform\")\n",
    "right = variogram(right_dist, structural_right, sigma=7, n_bins=20, binmethod=\"uniform\", plot=True)\n",
    "left = variogram(left_dist, structural_left, sigma=7, n_bins=20, binmethod=\"uniform\", plot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right effective range: -4.9869995398808555\n",
      "left effective range: -6.328191154877622\n",
      "right sill: 0.01897435033881789\n",
      "left sill: 0.046520439198973085\n"
     ]
    }
   ],
   "source": [
    "# map the gradient values to the left and right hemipsheres\n",
    "right['PC1'] = right['regions'].map(embedding_right.set_index('regions')['PC1'])\n",
    "left['PC1'] = left['regions'].map(embedding_left.set_index('regions')['PC1'])\n",
    "\n",
    "# center the PC1 values, differentiate unimodal to transmodal \n",
    "left_center = left[\"PC1\"].mean()\n",
    "right_center = right[\"PC1\"].mean()\n",
    "\n",
    "# get the unimodal and transmodal regions\n",
    "unimodal_right = right[right[\"PC1\"] < right_center]\n",
    "transmodal_right = right[right[\"PC1\"] > right_center]\n",
    "\n",
    "unimodal_left = left[left[\"PC1\"] < left_center]\n",
    "transmodal_left = left[left[\"PC1\"] > left_center]\n",
    "\n",
    "print(f\"right effective range: {unimodal_right[\"effective_range\"].mean()-transmodal_right[\"effective_range\"].mean()}\")\n",
    "print(f\"left effective range: {unimodal_left[\"effective_range\"].mean()- transmodal_left[\"effective_range\"].mean()}\")\n",
    "print(f\"right sill: {unimodal_right[\"sill\"].mean()-transmodal_right[\"sill\"].mean()}\")\n",
    "print(f\"left sill: {unimodal_left[\"sill\"].mean()- transmodal_left[\"sill\"].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find regions with high range and low sill\n",
    "rank_regions_table(right, high_range=True, high_sill=False, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to determine an adequate sigma, taking at the sigma which leads to a stable rmse and r2 estimates\n",
    "# df_sigma_choice_right = evaluate_sigma(right_dist, Gwr, n_bins=20, binmethod=\"uniform\")\n",
    "# df_sigma_choice_left = evaluate_sigma(left_dist, Gwl, n_bins=20, binmethod=\"uniform\")\n",
    "# create two subplots\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "# # right hemisphere\n",
    "# sigma_(df_sigma_choice_right, n=1.2, axes=axs[0])\n",
    "# # left hemisphere\n",
    "# sigma_(df_sigma_choice_left, n=1.2, axes=axs[1])\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to generate scatterplot\n",
    "rs_plt(left, embedding1, range=\"effective_range\", sill=\"sill\", ax=None, save_path=None, show=True)\n",
    "\n",
    "\n",
    "# normalise features across both hemispheres, for cross hemisphere comparison\n",
    "combined = pd.concat([left, right])\n",
    "scaler = QuantileTransformer()\n",
    "scaler.fit(combined[['effective_range', 'sill']])\n",
    "\n",
    "# preprocess and plot\n",
    "gradient_left = preprocess_data(left, embedding_left, scaler)\n",
    "gradient_right = preprocess_data(right, embedding_right, scaler)\n",
    "\n",
    "dendrogram(gradient_left, save=True, savename=\"dendrogram_left.png\")\n",
    "dendrogram(gradient_right, save=True, savename=\"dendrogram_right.png\")\n",
    "\n",
    "\n",
    "# assessing trends with distance from primary regions\n",
    "trend_(right, right_dist, feature=\"sill\", hemi=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation file\n",
    "annot_path = \"/Users/gabrielhaw/Connectome/misc/annot_fs7/lh.lausanne500.annot\"\n",
    "\n",
    "surf_map = map_surf_values_from_annot(\n",
    "    annot_path,\n",
    "    region_values=left,\n",
    "    label_col=\"regions\",\n",
    "    value_col=\"sill\"\n",
    ")\n",
    "\n",
    "# center your data around the mean from the DataFrame\n",
    "mean_range = left[\"sill\"].mean()\n",
    "surf_map_centered = surf_map - mean_range\n",
    "\n",
    "# clip outliers to prevent skewing\n",
    "clip_val = np.nanpercentile(np.abs(surf_map_centered), 90)\n",
    "vmin = -clip_val\n",
    "vmax = clip_val\n",
    "\n",
    "plot_left_hemisphere_with_colorbar(\n",
    "    surf_map=surf_map_centered,\n",
    "    fsaverage=fsaverage,\n",
    "    sulc_map=fsaverage_sulc,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    label='Effective range',\n",
    "    output_file='left_hemisphere_plot_sill.png',\n",
    "    dpi=600  # high-resolution\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
